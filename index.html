<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Sizhe Yang</title>
    <meta name="author" content="Sizhe Yang">
    <meta name="viewport" content="width=device-width, initial-scale=0.35, maximum-scale=1.0">
    <meta property="og:title" content="Sizhe Yang">
    <meta property="og:image" content="files\images\selfie.jpg">
    <meta property="og:url" content="https://yangsizhe.github.io/">
    <link rel="icon" type="image/png" href="files\images\icon_white_bg.jpg">
    <link rel="stylesheet" href="./files/style.css">
</head>

<body>
<div class="header noselect">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Sizhe Yang</h1>
            </div>
            <br>
            <!-- <div class="header-subtitle">
                Bachelor of Software Engineering <br>
                University of Electronic Science and Technology of China
            </div> -->
            <div class="header-links">
                <a class="btn" href="mailto:3599699144yang@gmail.com">Gmail</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=ue3SjGgAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> /
                <a class="btn" href="https://github.com/yangsizhe">GitHub</a> /
                <a class="btn" href="https://twitter.com/SizheYang111">Twitter</a> 
                <!-- <a class="btn" href="https://yanjieze.com/pdfs/YanjieZe_Academic_CV.pdf">CV</a> / -->
                <!-- <a class="btn" href="https://www.zhihu.com/people/luo-hua-qiu-jin">知乎</a> -->
            </div>
            <br>
            <br>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 64px;">
    <div>
        <p>I am a second-year Ph.D. student of <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab</a>, <a href="https://www.cuhk.edu.hk/english/index.html">the Chinese University of Hong Kong</a>, supervised by Prof. <a href="http://dahua.site/">Dahua Lin</a>. Prior to this, I received my Bachelor's degree in Software Engineering at <a href="https://www.uestc.edu.cn/">University of Electronic Science and Technology of China</a>.
            <br><br>
        Currently I work with <a href="https://oceanpang.github.io/">Jiangmiao Pang</a> and <a href="https://increase24.github.io/">Jia Zeng</a> at <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>, focusing on <span class="bold">Embodied AI</span>. 
        <!-- Currently I work with <a href="https://yanchaoyang.github.io/">Prof. Yanchao Yang</a> at <a href="https://www.hku.hk/">the University of Hong Kong</a>, focusing on <span class="bold">Embodied AI</span>.  -->
        <!-- Previously, I was a research assistant at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a> and <a href="https://sqz.ac.cn/">Shanghai Qi Zhi Institute</a>, advised by <a href="http://hxu.rocks/">Prof. Huazhe Xu</a>. -->
        </p>
    </div>
    <div>
        <h2 class="noselect">Research Interest</h2>
        <p>
            <span class="bold">Embodied AI</span> and <span class="bold">Robotics</span>.
        </p>
    </div>


    <style>
        .button {
            border: none;
            background-color: transparent;
            padding: 0;
            font: inherit;
            text-decoration: underline;
            cursor: pointer;
            outline: none;
        }
    
        .selected-button {
            border: none;
            background-color: transparent;
            padding: 0;
            font: inherit;
            text-decoration: underline;
            cursor: pointer;
            outline: none;
            color: #f09228;
        }
    </style>
    <div>
        <h2 class="noselect">Publications</h2>
        <p>
            See my <a href="https://scholar.google.com/citations?user=ue3SjGgAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> profile for a full list of publications.
        </p>
        <p>
            Representative papers are <span style="background-color: #e3f1f7;">highlighted</span>.
        </p>
        
        (* indicates equal contribution)<br><br>

        <div id="selected_publications">

            <!-- <div class="highlight publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/ultradexgrasp.jpg);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2504.13175">UltraDexGrasp: Learning Universal Dexterous Grasping for Bimanual Robots with Synthetic Data</a><br>
                    <span class="bold">Sizhe Yang</span>, Yiman Xie, Zhixuan Liang, Yang Tian, Jia Zeng, Dahua Lin, Jiangmiao Pang<br>
                    <span class="italic">In Submission to The International Conference on Robotics and Automation (<a href="https://2026.ieee-icra.org/">ICRA</a>)</span>, 2026 <span class="bold"></span><br>
                    <a class="btn btn-orange" href="https://yangsizhe.github.io/ultradexgrasp/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2504.13175">arXiv</a> / <a href="https://github.com/OpenRobotLab/UltraDexGrasp/">code</a>
                </div>
            </div>

            <div class="highlight publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/ultradexgrasp.jpg);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2504.13175">One-Policy-Fits-All: Geometry-Aware Action Latents for Cross-Embodiment Manipulation</a><br>
                    Juncheng Mu*, <span class="bold">Sizhe Yang*</span>, Hojin Bae*, Feiyu Jia, Qingwei Ben, Boyi Li, Huazhe Xu, Jiangmiao Pang<br>
                    <span class="italic">In Submission to The International Conference on Robotics and Automation (<a href="https://2026.ieee-icra.org/">ICRA</a>)</span>, 2026 <span class="bold"></span><br>
                    <a class="btn btn-orange" href="https://yangsizhe.github.io/ultradexgrasp/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2504.13175">arXiv</a> / <a href="https://github.com/OpenRobotLab/UltraDexGrasp/">code</a>
                </div>
            </div> -->

            <div class="highlight publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/robosplat.jpg);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2504.13175">Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation</a><br>
                    <span class="bold">Sizhe Yang*</span>, Wenye Yu*, Jia Zeng, Jun Lv, Kerui Ren, Cewu Lu, Dahua Lin, Jiangmiao Pang<br>
                    <span class="italic">Robotics: Science and Systems (<a href="https://roboticsconference.org/">RSS</a>)</span>, 2025 <span class="bold">(Oral)</span><br>
                    <a class="btn btn-orange" href="https://yangsizhe.github.io/robosplat/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2504.13175">arXiv</a> / <a href="https://github.com/OpenRobotLab/RoboSplat/">code</a>
                </div>
            </div>

            <div class="highlight publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/Seer.png);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2412.15109">Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation</a><br>
                    <span class="bold">Sizhe Yang*</span>, Yang Tian* (* equal contribution, author ordering determined by coin flip), Jia Zeng, Ping Wang, Dahua Lin, Hao Dong, Jiangmiao Pang<br>
                    <!-- Yang Tian*, <span class="bold">Sizhe Yang*</span>, Jia Zeng, Ping Wang, Dahua Lin, Hao Dong, Jiangmiao Pang<br> -->
                    <span class="italic">The International Conference on Learning Representations (<a href="https://iclr.cc">ICLR</a>)</span>, 2025 <span class="bold">(Oral)</span><br>
                    <a class="btn btn-orange" href="https://nimolty.github.io/Seer/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2412.15109">arXiv</a> / <a href="https://github.com/OpenRobotLab/Seer">code</a>
                </div>
            </div>

            <div class="highlight publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/MoVie.gif);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2307.00972">MoVie: Visual Model-Based Policy Adaptation for View Generalization</a><br>
                    <span class="bold">Sizhe Yang*</span>, Yanjie Ze*, Huazhe Xu<br>
                    <span class="italic">Conference on Neural Information Processing Systems (<a href="https://nips.cc/Conferences/2023">NeurIPS</a>)</span>, 2023<br>
                    <a class="btn btn-orange" href="https://yangsizhe.github.io/MoVie/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2307.00972">arXiv</a> / <a href="https://github.com/yangsizhe/MoVie/">code</a>
                </div>
            </div>

            <div class="publication row clearfix">
                <div class="row-media" style="background-image: url(files/images/RL-ViGen.jpg);"></div>
                <div class="row-text">
                    <a class="publication-title bold" href="https://arxiv.org/abs/2307.10224">RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization</a><br>
                    Zhecheng Yuan*, <span class="bold">Sizhe Yang*</span>, Pu Hua, Can Chang, Kaizhe Hu, Xiaolong Wang, Huazhe Xu<br>
                    <span class="italic">Conference on Neural Information Processing Systems Datasets and Benchmarks Track (<a href="https://nips.cc/Conferences/2023">NeurIPS</a>)</span>, 2023<br>
                    <a class="btn btn-orange" href="https://gemcollector.github.io/RL-ViGen/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2307.10224">arXiv</a> / <a href="https://github.com/gemcollector/RL-ViGen">code</a>
                </div>
            </div>

        </div>
    </div>


    <div>
        <h2 class="noselect">Honors and Awards</h2>
        • SenseTime Scholarship (selects 30 undergraduates in the field of AI from all over China annually) <br>
        • National Scholarship for 2022/2023 academic year <br>
        • National Scholarship for 2021/2022 academic year <br>
        • National Scholarship for 2020/2021 academic year <br>
    </div>

    <div>
        <h2 class="noselect">Academic Services</h2>
        I am willing to help build the academic community. I serve as the reviewer for <br><br>
        • TMLR <br>
        • NeurIPS <br>
        • ICRA <br>
    </div>


</div>


<div class="footer noselect">
    <div class="footer-content">
        © 2025 Sizhe Yang. Template from <a style="color: rgb(0, 0, 0); text-decoration: underline;" href="https://yanjieze.com/">Yanjie Ze</a>.
    </div>
</div>

</body>
</html>